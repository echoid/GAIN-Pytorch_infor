{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creator: Dhanajit Brahma\n",
    "\n",
    "Adapted from the original implementation in tensorflow from here: https://github.com/jsyoon0823/GAIN\n",
    "\n",
    "Generative Adversarial Imputation Networks (GAIN) Implementation on Letter and Spam Dataset\n",
    "\n",
    "Reference: J. Yoon, J. Jordon, M. van der Schaar, \"GAIN: Missing Data Imputation using Generative Adversarial Nets,\" ICML, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Packages\n",
    "import torch\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = 'Spam.csv'  # 'Letter.csv' for Letter dataset an 'Spam.csv' for Spam dataset\n",
    "use_gpu = False  # set it to True to use GPU and False to use CPU\n",
    "\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% System Parameters\n",
    "# 1. Mini batch size\n",
    "mb_size = 32\n",
    "# 2. Missing rate\n",
    "p_miss = 0.2\n",
    "# 3. Hint rate\n",
    "p_hint = 0.9\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0.8\n",
    "\n",
    "#%% Data\n",
    "\n",
    "# Data generation\n",
    "Data = np.loadtxt(dataset_file, delimiter=\",\",skiprows=1)\n",
    "\n",
    "# Parameters\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "\n",
    "#%% Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "#%% Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "#%% Necessary Functions\n",
    "\n",
    "# 1. Xavier Initialization Definition\n",
    "# def xavier_init(size):\n",
    "#     in_dim = size[0]\n",
    "#     xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "#     return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size = size, scale = xavier_stddev)\n",
    "    \n",
    "# Hint Vector Generation\n",
    "def sample_M(m, n, p):\n",
    "    A = np.random.uniform(0., 1., size = [m, n])\n",
    "    B = A > p\n",
    "    C = 1.*B\n",
    "    return C\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAIN Architecture   \n",
    "GAIN Consists of 3 Components\n",
    "- Generator\n",
    "- Discriminator\n",
    "- Hint Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 1. Discriminator\n",
    "if use_gpu is True:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")       # Output is multi-variate\n",
    "else:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)       # Output is multi-variate\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "\n",
    "#%% 2. Generator\n",
    "if use_gpu is True:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")\n",
    "else:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAIN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 1. Generator\n",
    "def generator(new_x,m):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,m])  # Mask + Data Concatenate\n",
    "    G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
    "    G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)   \n",
    "    G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "    \n",
    "    return G_prob\n",
    "\n",
    "#%% 2. Discriminator\n",
    "def discriminator(new_x, h):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,h])  # Hint + Data Concatenate\n",
    "    D_h1 = F.relu(torch.matmul(inputs, D_W1) + D_b1)  \n",
    "    D_h2 = F.relu(torch.matmul(D_h1, D_W2) + D_b2)\n",
    "    D_logit = torch.matmul(D_h2, D_W3) + D_b3\n",
    "    D_prob = torch.sigmoid(D_logit)  # [0,1] Probability Output\n",
    "    \n",
    "    return D_prob\n",
    "\n",
    "#%% 3. Other functions\n",
    "# Random sample generator for Z\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "\n",
    "# Mini-batch generation\n",
    "def sample_idx(m, n):\n",
    "    A = np.random.permutation(m)\n",
    "    idx = A[:n]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_columnwise_kl(real_data, fake_data):\n",
    "    kl_divergences = []\n",
    "    \n",
    "    for col_idx in range(real_data.shape[1]):  # Iterate over columns\n",
    "        real_column = real_data[:, col_idx]\n",
    "        fake_column = fake_data[:, col_idx]\n",
    "        \n",
    "        # Calculate mean and covariance for each distribution\n",
    "        mean_real = torch.mean(real_column)\n",
    "        cov_real = torch.diag(torch.var(real_column, unbiased=False))\n",
    "        \n",
    "        mean_fake = torch.mean(fake_column)\n",
    "        cov_fake = torch.diag(torch.var(fake_column, unbiased=False))\n",
    "        \n",
    "        # Calculate KL divergence using the formula\n",
    "        kl_div = 0.5 * (torch.trace(torch.inverse(cov_fake) @ cov_real) +\n",
    "                        (mean_fake - mean_real).T @ torch.inverse(cov_fake) @ (mean_fake - mean_real) -\n",
    "                        real_data.shape[1] + torch.logdet(cov_fake) - torch.logdet(cov_real))\n",
    "        \n",
    "        kl_divergences.append(kl_div.item())\n",
    "    \n",
    "    return kl_divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3002, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "input = F.log_softmax(torch.randn(3, 5, requires_grad=True), dim=1)\n",
    "target = F.softmax(torch.rand(3, 5), dim=1)\n",
    "kl_loss = F.kl_div(input, target,reduction=\"batchmean\")\n",
    "print(kl_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAIN Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(M, New_X, H):\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    D_loss = -torch.mean(M * torch.log(D_prob + 1e-8) + (1-M) * torch.log(1. - D_prob + 1e-8))\n",
    "    return D_loss\n",
    "\n",
    "def generator_loss(X, M, New_X, H):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    G_loss1 = -torch.mean((1-M) * torch.log(D_prob + 1e-8))\n",
    "    MSE_train_loss = torch.mean((M * New_X - M * G_sample)**2) / torch.mean(M)\n",
    "\n",
    "    kl_loss = F.kl_div(X, G_sample,reduction=\"batchmean\")\n",
    "\n",
    "    G_loss = G_loss1 + alpha * MSE_train_loss + kl_loss\n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return G_loss, MSE_train_loss, MSE_test_loss,kl_loss\n",
    "    \n",
    "def test_loss(X, M, New_X):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return MSE_test_loss, G_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_D = torch.optim.Adam(params=theta_D)\n",
    "optimizer_G = torch.optim.Adam(params=theta_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daebe3b0d61e459b9e200602c2422e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\tTrain_loss: 0.3059\tTest_loss: 0.248\n",
      "Iter: 100\tTrain_loss: 0.3038\tTest_loss: 0.2453\n",
      "Iter: 200\tTrain_loss: 0.3028\tTest_loss: 0.2434\n",
      "Iter: 300\tTrain_loss: 0.3027\tTest_loss: 0.2474\n",
      "Iter: 400\tTrain_loss: 0.3027\tTest_loss: 0.2456\n",
      "Iter: 500\tTrain_loss: 0.3051\tTest_loss: 0.2443\n",
      "Iter: 600\tTrain_loss: 0.3039\tTest_loss: 0.2483\n",
      "Iter: 700\tTrain_loss: 0.3039\tTest_loss: 0.2454\n",
      "Iter: 800\tTrain_loss: 0.3045\tTest_loss: 0.2445\n",
      "Iter: 900\tTrain_loss: 0.3013\tTest_loss: 0.2441\n",
      "Iter: 1000\tTrain_loss: 0.3033\tTest_loss: 0.2414\n",
      "Iter: 1100\tTrain_loss: 0.3045\tTest_loss: 0.2435\n",
      "Iter: 1200\tTrain_loss: 0.3028\tTest_loss: 0.2429\n",
      "Iter: 1300\tTrain_loss: 0.3024\tTest_loss: 0.2431\n",
      "Iter: 1400\tTrain_loss: 0.3033\tTest_loss: 0.2421\n",
      "Iter: 1500\tTrain_loss: 0.3027\tTest_loss: 0.2418\n",
      "Iter: 1600\tTrain_loss: 0.3023\tTest_loss: 0.2413\n",
      "Iter: 1700\tTrain_loss: 0.3049\tTest_loss: 0.2382\n",
      "Iter: 1800\tTrain_loss: 0.3047\tTest_loss: 0.2376\n",
      "Iter: 1900\tTrain_loss: 0.3042\tTest_loss: 0.2388\n",
      "Iter: 2000\tTrain_loss: 0.3047\tTest_loss: 0.2385\n",
      "Iter: 2100\tTrain_loss: 0.3047\tTest_loss: 0.2398\n",
      "Iter: 2200\tTrain_loss: 0.3038\tTest_loss: 0.2418\n",
      "Iter: 2300\tTrain_loss: 0.3018\tTest_loss: 0.2359\n",
      "Iter: 2400\tTrain_loss: 0.3052\tTest_loss: 0.2363\n",
      "Iter: 2500\tTrain_loss: 0.3027\tTest_loss: 0.2367\n",
      "Iter: 2600\tTrain_loss: 0.3032\tTest_loss: 0.2377\n",
      "Iter: 2700\tTrain_loss: 0.3034\tTest_loss: 0.2354\n",
      "Iter: 2800\tTrain_loss: 0.3012\tTest_loss: 0.2373\n",
      "Iter: 2900\tTrain_loss: 0.3052\tTest_loss: 0.2382\n",
      "Iter: 3000\tTrain_loss: 0.3048\tTest_loss: 0.2325\n",
      "Iter: 3100\tTrain_loss: 0.3039\tTest_loss: 0.2389\n",
      "Iter: 3200\tTrain_loss: 0.3041\tTest_loss: 0.2372\n",
      "Iter: 3300\tTrain_loss: 0.3046\tTest_loss: 0.236\n",
      "Iter: 3400\tTrain_loss: 0.3051\tTest_loss: 0.2357\n",
      "Iter: 3500\tTrain_loss: 0.3025\tTest_loss: 0.234\n",
      "Iter: 3600\tTrain_loss: 0.3046\tTest_loss: 0.2317\n",
      "Iter: 3700\tTrain_loss: 0.3054\tTest_loss: 0.2356\n",
      "Iter: 3800\tTrain_loss: 0.3036\tTest_loss: 0.2353\n",
      "Iter: 3900\tTrain_loss: 0.3032\tTest_loss: 0.2307\n",
      "Iter: 4000\tTrain_loss: 0.3033\tTest_loss: 0.2336\n",
      "Iter: 4100\tTrain_loss: 0.3041\tTest_loss: 0.2345\n",
      "Iter: 4200\tTrain_loss: 0.3018\tTest_loss: 0.2296\n",
      "Iter: 4300\tTrain_loss: 0.3028\tTest_loss: 0.2315\n",
      "Iter: 4400\tTrain_loss: 0.3043\tTest_loss: 0.2363\n",
      "Iter: 4500\tTrain_loss: 0.3024\tTest_loss: 0.2305\n",
      "Iter: 4600\tTrain_loss: 0.3053\tTest_loss: 0.2342\n",
      "Iter: 4700\tTrain_loss: 0.303\tTest_loss: 0.2314\n",
      "Iter: 4800\tTrain_loss: 0.3016\tTest_loss: 0.2287\n",
      "Iter: 4900\tTrain_loss: 0.3014\tTest_loss: 0.228\n",
      "Iter: 5000\tTrain_loss: 0.3055\tTest_loss: 0.2331\n",
      "Iter: 5100\tTrain_loss: 0.3035\tTest_loss: 0.2279\n",
      "Iter: 5200\tTrain_loss: 0.3032\tTest_loss: 0.2321\n",
      "Iter: 5300\tTrain_loss: 0.3022\tTest_loss: 0.2323\n",
      "Iter: 5400\tTrain_loss: 0.3026\tTest_loss: 0.229\n",
      "Iter: 5500\tTrain_loss: 0.3034\tTest_loss: 0.229\n",
      "Iter: 5600\tTrain_loss: 0.3024\tTest_loss: 0.2313\n",
      "Iter: 5700\tTrain_loss: 0.3026\tTest_loss: 0.2279\n",
      "Iter: 5800\tTrain_loss: 0.3013\tTest_loss: 0.2292\n",
      "Iter: 5900\tTrain_loss: 0.3039\tTest_loss: 0.2339\n",
      "Iter: 6000\tTrain_loss: 0.3038\tTest_loss: 0.2302\n",
      "Iter: 6100\tTrain_loss: 0.3052\tTest_loss: 0.2292\n",
      "Iter: 6200\tTrain_loss: 0.3038\tTest_loss: 0.2317\n",
      "Iter: 6300\tTrain_loss: 0.3029\tTest_loss: 0.231\n",
      "Iter: 6400\tTrain_loss: 0.3042\tTest_loss: 0.2297\n",
      "Iter: 6500\tTrain_loss: 0.3037\tTest_loss: 0.2302\n",
      "Iter: 6600\tTrain_loss: 0.3029\tTest_loss: 0.2271\n",
      "Iter: 6700\tTrain_loss: 0.3017\tTest_loss: 0.2302\n",
      "Iter: 6800\tTrain_loss: 0.3053\tTest_loss: 0.2295\n",
      "Iter: 6900\tTrain_loss: 0.301\tTest_loss: 0.2247\n",
      "Iter: 7000\tTrain_loss: 0.3044\tTest_loss: 0.2323\n",
      "Iter: 7100\tTrain_loss: 0.3033\tTest_loss: 0.2245\n",
      "Iter: 7200\tTrain_loss: 0.304\tTest_loss: 0.2229\n",
      "Iter: 7300\tTrain_loss: 0.3035\tTest_loss: 0.2289\n",
      "Iter: 7400\tTrain_loss: 0.3026\tTest_loss: 0.2239\n",
      "Iter: 7500\tTrain_loss: 0.3034\tTest_loss: 0.2266\n",
      "Iter: 7600\tTrain_loss: 0.3038\tTest_loss: 0.2213\n",
      "Iter: 7700\tTrain_loss: 0.3034\tTest_loss: 0.2283\n",
      "Iter: 7800\tTrain_loss: 0.3033\tTest_loss: 0.2266\n",
      "Iter: 7900\tTrain_loss: 0.303\tTest_loss: 0.2243\n",
      "Iter: 8000\tTrain_loss: 0.3055\tTest_loss: 0.2247\n",
      "Iter: 8100\tTrain_loss: 0.305\tTest_loss: 0.2262\n",
      "Iter: 8200\tTrain_loss: 0.3042\tTest_loss: 0.2233\n",
      "Iter: 8300\tTrain_loss: 0.3005\tTest_loss: 0.2235\n",
      "Iter: 8400\tTrain_loss: 0.3036\tTest_loss: 0.2233\n",
      "Iter: 8500\tTrain_loss: 0.3041\tTest_loss: 0.2244\n",
      "Iter: 8600\tTrain_loss: 0.3023\tTest_loss: 0.2253\n",
      "Iter: 8700\tTrain_loss: 0.3048\tTest_loss: 0.221\n",
      "Iter: 8800\tTrain_loss: 0.3031\tTest_loss: 0.2215\n",
      "Iter: 8900\tTrain_loss: 0.3024\tTest_loss: 0.2277\n",
      "Iter: 9000\tTrain_loss: 0.3036\tTest_loss: 0.2203\n",
      "Iter: 9100\tTrain_loss: 0.3039\tTest_loss: 0.2204\n",
      "Iter: 9200\tTrain_loss: 0.3043\tTest_loss: 0.2236\n",
      "Iter: 9300\tTrain_loss: 0.3035\tTest_loss: 0.2223\n",
      "Iter: 9400\tTrain_loss: 0.305\tTest_loss: 0.2237\n",
      "Iter: 9500\tTrain_loss: 0.3028\tTest_loss: 0.2218\n",
      "Iter: 9600\tTrain_loss: 0.305\tTest_loss: 0.218\n",
      "Iter: 9700\tTrain_loss: 0.3029\tTest_loss: 0.22\n",
      "Iter: 9800\tTrain_loss: 0.3026\tTest_loss: 0.2214\n",
      "Iter: 9900\tTrain_loss: 0.3043\tTest_loss: 0.2206\n",
      "Iter: 10000\tTrain_loss: 0.3038\tTest_loss: 0.2241\n",
      "Iter: 10100\tTrain_loss: 0.303\tTest_loss: 0.2206\n",
      "Iter: 10200\tTrain_loss: 0.3035\tTest_loss: 0.2233\n",
      "Iter: 10300\tTrain_loss: 0.3042\tTest_loss: 0.2207\n",
      "Iter: 10400\tTrain_loss: 0.3058\tTest_loss: 0.2217\n",
      "Iter: 10500\tTrain_loss: 0.3048\tTest_loss: 0.2261\n",
      "Iter: 10600\tTrain_loss: 0.3035\tTest_loss: 0.223\n",
      "Iter: 10700\tTrain_loss: 0.3046\tTest_loss: 0.222\n",
      "Iter: 10800\tTrain_loss: 0.3045\tTest_loss: 0.2214\n",
      "Iter: 10900\tTrain_loss: 0.3031\tTest_loss: 0.2212\n",
      "Iter: 11000\tTrain_loss: 0.3038\tTest_loss: 0.2151\n",
      "Iter: 11100\tTrain_loss: 0.303\tTest_loss: 0.2212\n",
      "Iter: 11200\tTrain_loss: 0.3035\tTest_loss: 0.2225\n",
      "Iter: 11300\tTrain_loss: 0.3023\tTest_loss: 0.2169\n",
      "Iter: 11400\tTrain_loss: 0.3052\tTest_loss: 0.2163\n",
      "Iter: 11500\tTrain_loss: 0.3048\tTest_loss: 0.2175\n",
      "Iter: 11600\tTrain_loss: 0.3048\tTest_loss: 0.2186\n",
      "Iter: 11700\tTrain_loss: 0.3058\tTest_loss: 0.2218\n",
      "Iter: 11800\tTrain_loss: 0.3042\tTest_loss: 0.2227\n",
      "Iter: 11900\tTrain_loss: 0.3041\tTest_loss: 0.2177\n",
      "Iter: 12000\tTrain_loss: 0.3054\tTest_loss: 0.2184\n",
      "Iter: 12100\tTrain_loss: 0.3038\tTest_loss: 0.2225\n",
      "Iter: 12200\tTrain_loss: 0.3045\tTest_loss: 0.2157\n",
      "Iter: 12300\tTrain_loss: 0.3041\tTest_loss: 0.2132\n",
      "Iter: 12400\tTrain_loss: 0.3033\tTest_loss: 0.2173\n",
      "Iter: 12500\tTrain_loss: 0.3049\tTest_loss: 0.2172\n",
      "Iter: 12600\tTrain_loss: 0.3051\tTest_loss: 0.2171\n",
      "Iter: 12700\tTrain_loss: 0.3033\tTest_loss: 0.2177\n",
      "Iter: 12800\tTrain_loss: 0.3039\tTest_loss: 0.2168\n",
      "Iter: 12900\tTrain_loss: 0.3069\tTest_loss: 0.2168\n",
      "Iter: 13000\tTrain_loss: 0.3044\tTest_loss: 0.2171\n",
      "Iter: 13100\tTrain_loss: 0.3045\tTest_loss: 0.2182\n",
      "Iter: 13200\tTrain_loss: 0.3041\tTest_loss: 0.2181\n",
      "Iter: 13300\tTrain_loss: 0.3041\tTest_loss: 0.2152\n",
      "Iter: 13400\tTrain_loss: 0.3055\tTest_loss: 0.2131\n",
      "Iter: 13500\tTrain_loss: 0.3039\tTest_loss: 0.2189\n",
      "Iter: 13600\tTrain_loss: 0.3042\tTest_loss: 0.2174\n",
      "Iter: 13700\tTrain_loss: 0.3057\tTest_loss: 0.2176\n",
      "Iter: 13800\tTrain_loss: 0.3053\tTest_loss: 0.217\n",
      "Iter: 13900\tTrain_loss: 0.3047\tTest_loss: 0.2217\n",
      "Iter: 14000\tTrain_loss: 0.3049\tTest_loss: 0.2164\n",
      "Iter: 14100\tTrain_loss: 0.3054\tTest_loss: 0.2202\n",
      "Iter: 14200\tTrain_loss: 0.3045\tTest_loss: 0.2182\n",
      "Iter: 14300\tTrain_loss: 0.3038\tTest_loss: 0.216\n",
      "Iter: 14400\tTrain_loss: 0.3052\tTest_loss: 0.2193\n",
      "Iter: 14500\tTrain_loss: 0.3045\tTest_loss: 0.2204\n",
      "Iter: 14600\tTrain_loss: 0.3038\tTest_loss: 0.219\n",
      "Iter: 14700\tTrain_loss: 0.3044\tTest_loss: 0.2169\n",
      "Iter: 14800\tTrain_loss: 0.3045\tTest_loss: 0.2204\n",
      "Iter: 14900\tTrain_loss: 0.3031\tTest_loss: 0.2144\n",
      "Iter: 15000\tTrain_loss: 0.3045\tTest_loss: 0.2197\n",
      "Iter: 15100\tTrain_loss: 0.3049\tTest_loss: 0.2133\n",
      "Iter: 15200\tTrain_loss: 0.304\tTest_loss: 0.2167\n",
      "Iter: 15300\tTrain_loss: 0.3035\tTest_loss: 0.2159\n",
      "Iter: 15400\tTrain_loss: 0.3047\tTest_loss: 0.2163\n",
      "Iter: 15500\tTrain_loss: 0.3048\tTest_loss: 0.2176\n",
      "Iter: 15600\tTrain_loss: 0.3052\tTest_loss: 0.2195\n",
      "Iter: 15700\tTrain_loss: 0.3043\tTest_loss: 0.2182\n",
      "Iter: 15800\tTrain_loss: 0.305\tTest_loss: 0.2152\n",
      "Iter: 15900\tTrain_loss: 0.3043\tTest_loss: 0.22\n",
      "Iter: 16000\tTrain_loss: 0.3053\tTest_loss: 0.2172\n",
      "Iter: 16100\tTrain_loss: 0.3048\tTest_loss: 0.2119\n",
      "Iter: 16200\tTrain_loss: 0.3053\tTest_loss: 0.2181\n",
      "Iter: 16300\tTrain_loss: 0.3047\tTest_loss: 0.2198\n",
      "Iter: 16400\tTrain_loss: 0.3038\tTest_loss: 0.2163\n",
      "Iter: 16500\tTrain_loss: 0.3035\tTest_loss: 0.2206\n",
      "Iter: 16600\tTrain_loss: 0.3034\tTest_loss: 0.2141\n",
      "Iter: 16700\tTrain_loss: 0.3042\tTest_loss: 0.22\n",
      "Iter: 16800\tTrain_loss: 0.3063\tTest_loss: 0.2126\n",
      "Iter: 16900\tTrain_loss: 0.3044\tTest_loss: 0.2166\n",
      "Iter: 17000\tTrain_loss: 0.3047\tTest_loss: 0.216\n",
      "Iter: 17100\tTrain_loss: 0.3039\tTest_loss: 0.2149\n",
      "Iter: 17200\tTrain_loss: 0.3056\tTest_loss: 0.2172\n",
      "Iter: 17300\tTrain_loss: 0.3043\tTest_loss: 0.2152\n",
      "Iter: 17400\tTrain_loss: 0.3046\tTest_loss: 0.2174\n",
      "Iter: 17500\tTrain_loss: 0.3053\tTest_loss: 0.2141\n",
      "Iter: 17600\tTrain_loss: 0.305\tTest_loss: 0.2217\n",
      "Iter: 17700\tTrain_loss: 0.3029\tTest_loss: 0.2113\n",
      "Iter: 17800\tTrain_loss: 0.3062\tTest_loss: 0.2194\n",
      "Iter: 17900\tTrain_loss: 0.3041\tTest_loss: 0.2131\n",
      "Iter: 18000\tTrain_loss: 0.3042\tTest_loss: 0.2133\n",
      "Iter: 18100\tTrain_loss: 0.3049\tTest_loss: 0.2172\n",
      "Iter: 18200\tTrain_loss: 0.3061\tTest_loss: 0.2175\n",
      "Iter: 18300\tTrain_loss: 0.3041\tTest_loss: 0.2107\n",
      "Iter: 18400\tTrain_loss: 0.3035\tTest_loss: 0.2153\n",
      "Iter: 18500\tTrain_loss: 0.3053\tTest_loss: 0.213\n",
      "Iter: 18600\tTrain_loss: 0.3052\tTest_loss: 0.2124\n",
      "Iter: 18700\tTrain_loss: 0.3056\tTest_loss: 0.2186\n",
      "Iter: 18800\tTrain_loss: 0.3052\tTest_loss: 0.2159\n",
      "Iter: 18900\tTrain_loss: 0.3043\tTest_loss: 0.2139\n",
      "Iter: 19000\tTrain_loss: 0.3045\tTest_loss: 0.2103\n",
      "Iter: 19100\tTrain_loss: 0.3038\tTest_loss: 0.214\n",
      "Iter: 19200\tTrain_loss: 0.3039\tTest_loss: 0.212\n",
      "Iter: 19300\tTrain_loss: 0.3054\tTest_loss: 0.2143\n",
      "Iter: 19400\tTrain_loss: 0.3064\tTest_loss: 0.2138\n",
      "Iter: 19500\tTrain_loss: 0.3056\tTest_loss: 0.2154\n",
      "Iter: 19600\tTrain_loss: 0.3048\tTest_loss: 0.2111\n",
      "Iter: 19700\tTrain_loss: 0.3059\tTest_loss: 0.2134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/epochoid/Desktop/GAIN-Pytorch_infor/GAIN-pretty-tqdm.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/epochoid/Desktop/GAIN-Pytorch_infor/GAIN-pretty-tqdm.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m optimizer_G\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/epochoid/Desktop/GAIN-Pytorch_infor/GAIN-pretty-tqdm.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m G_loss_curr, MSE_train_loss_curr, MSE_test_loss_curr \u001b[39m=\u001b[39m generator_loss(X\u001b[39m=\u001b[39mX_mb, M\u001b[39m=\u001b[39mM_mb, New_X\u001b[39m=\u001b[39mNew_X_mb, H\u001b[39m=\u001b[39mH_mb)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/epochoid/Desktop/GAIN-Pytorch_infor/GAIN-pretty-tqdm.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m G_loss_curr\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/epochoid/Desktop/GAIN-Pytorch_infor/GAIN-pretty-tqdm.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m optimizer_G\u001b[39m.\u001b[39mstep()    \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/epochoid/Desktop/GAIN-Pytorch_infor/GAIN-pretty-tqdm.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m#%% Intermediate Losses\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%% Start Iterations\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "iterations = []\n",
    "\n",
    "for it in tqdm(range(20000)):    \n",
    "    \n",
    "    #%% Inputs\n",
    "    mb_idx = sample_idx(Train_No, mb_size)\n",
    "    X_mb = trainX[mb_idx,:]  \n",
    "    \n",
    "    Z_mb = sample_Z(mb_size, Dim) \n",
    "    M_mb = trainM[mb_idx,:]  \n",
    "    H_mb1 = sample_M(mb_size, Dim, 1-p_hint)\n",
    "    H_mb = M_mb * H_mb1\n",
    "    \n",
    "    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "    \n",
    "    if use_gpu is True:\n",
    "        X_mb = torch.tensor(X_mb, device=\"cuda\")\n",
    "        M_mb = torch.tensor(M_mb, device=\"cuda\")\n",
    "        H_mb = torch.tensor(H_mb, device=\"cuda\")\n",
    "        New_X_mb = torch.tensor(New_X_mb, device=\"cuda\")\n",
    "    else:\n",
    "        X_mb = torch.tensor(X_mb)\n",
    "        M_mb = torch.tensor(M_mb)\n",
    "        H_mb = torch.tensor(H_mb)\n",
    "        New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "    D_loss_curr = discriminator_loss(M=M_mb, New_X=New_X_mb, H=H_mb)\n",
    "    D_loss_curr.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    optimizer_G.zero_grad()\n",
    "    G_loss_curr, MSE_train_loss_curr, MSE_test_loss_curr,kl_loss = generator_loss(X=X_mb, M=M_mb, New_X=New_X_mb, H=H_mb)\n",
    "    G_loss_curr.backward()\n",
    "    optimizer_G.step()    \n",
    "        \n",
    "    #%% Intermediate Losses\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}'.format(it),end='\\t')\n",
    "        print('Train_loss: {:.4}'.format(np.sqrt(MSE_train_loss_curr.item())),end='\\t')\n",
    "        print('Test_loss: {:.4}'.format(np.sqrt(MSE_test_loss_curr.item())))\n",
    "\n",
    "\n",
    "            # Append the current iteration and losses to the lists\n",
    "        iterations.append(it)\n",
    "        train_losses.append(np.sqrt(MSE_train_loss_curr.item()))\n",
    "        test_losses.append(np.sqrt(MSE_test_loss_curr.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure and a set of subplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot train losses\n",
    "ax.plot(iterations, train_losses, label='Train Loss', color='blue')\n",
    "\n",
    "# Plot test losses\n",
    "ax.plot(iterations, test_losses, label='Test Loss', color='red')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Intermediate Train and Test Losses')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test RMSE: 0.3094698604777049\n"
     ]
    }
   ],
   "source": [
    "Z_mb = sample_Z(Test_No, Dim) \n",
    "M_mb = testM\n",
    "X_mb = testX\n",
    "        \n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "if use_gpu is True:\n",
    "    X_mb = torch.tensor(X_mb, device='cuda')\n",
    "    M_mb = torch.tensor(M_mb, device='cuda')\n",
    "    New_X_mb = torch.tensor(New_X_mb, device='cuda')\n",
    "else:\n",
    "    X_mb = torch.tensor(X_mb)\n",
    "    M_mb = torch.tensor(M_mb)\n",
    "    New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "MSE_final, Sample = test_loss(X=X_mb, M=M_mb, New_X=New_X_mb)\n",
    "        \n",
    "print('Final Test RMSE: ' + str(np.sqrt(MSE_final.item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed test data:\n",
      "[[0.11013213 0.02801120 0.06470587 ... 0.00458375 0.01281538 0.14008838]\n",
      " [0.00000000 0.00000000 0.00000000 ... 0.00172492 0.00270324 0.00542929]\n",
      " [0.00000000 0.32472636 0.33435693 ... 0.00038856 0.00010012 0.00056818]\n",
      " ...\n",
      " [0.31423297 0.00000000 0.00000000 ... 0.00000000 0.30596677 0.30564378]\n",
      " [0.00000000 0.00000000 0.00000000 ... 0.00118656 0.00080096 0.00183081]\n",
      " [0.33588246 0.33183913 0.00000000 ... 0.00075261 0.00060072 0.00467172]]\n"
     ]
    }
   ],
   "source": [
    "imputed_data = M_mb * X_mb + (1-M_mb) * Sample\n",
    "print(\"Imputed test data:\")\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.8f}\".format(x)})\n",
    "\n",
    "if use_gpu is True:\n",
    "    print(imputed_data.cpu().detach().numpy())\n",
    "else:\n",
    "    print(imputed_data.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
